# -*- coding: utf-8 -*-
"""audioTranslator

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ntNOD2VCVDTZbuQHHlxl-5N9hc0-h835
"""

# 1) Instalar dependÃªncias
!pip install SpeechRecognition pydub transformers sentencepiece torch

# 2) Imports
import os
import speech_recognition as sr
from pydub import AudioSegment
from google.colab import files
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

# 3) FunÃ§Ã£o para conversÃ£o de Ã¡udio
def convert_to_wav(input_file):
    filename, ext = os.path.splitext(input_file)
    if ext.lower() != ".wav":
        sound = AudioSegment.from_file(input_file)
        wav_filename = filename + ".wav"
        sound.export(wav_filename, format="wav")
        return wav_filename
    return input_file

# 4) Upload do Ã¡udio
print("ğŸ“¥ FaÃ§a o upload do seu Ã¡udio em inglÃªs:")
uploaded = files.upload()
audio_file = list(uploaded.keys())[0]
print(f"ğŸ”Š Arquivo recebido: {audio_file}")

# 5) ConversÃ£o se necessÃ¡rio
audio_wav = convert_to_wav(audio_file)

# 6) Reconhecimento de fala
r = sr.Recognizer()
with sr.AudioFile(audio_wav) as source:
    audio_data = r.record(source)

try:
    print("ğŸ“ Transcrevendo Ã¡udio...")
    texto_en = r.recognize_google(audio_data, language="en-US")
    print(f"\nğŸ‡¬ğŸ‡§ Texto em inglÃªs:\n{texto_en}")
except sr.UnknownValueError:
    print("âŒ NÃ£o foi possÃ­vel entender o Ã¡udio.")
    raise SystemExit
except sr.RequestError as e:
    print(f"âŒ Erro na API de voz: {e}")
    raise SystemExit

# 7) TraduÃ§Ã£o com NLLB (Meta)
print("\nğŸŒ Traduzindo para portuguÃªs com NLLB...")
model_name = "facebook/nllb-200-distilled-600M"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

# Definir os tokens de idioma
src_lang = "eng_Latn"
tgt_lang = "por_Latn"

# Preparar entrada
inputs = tokenizer(texto_en, return_tensors="pt", padding=True)
inputs["forced_bos_token_id"] = tokenizer.convert_tokens_to_ids(tgt_lang)

# Gerar traduÃ§Ã£o
translated_tokens = model.generate(**inputs, max_length=1000)
translated_text = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]

print(f"\nğŸ‡§ğŸ‡· TraduÃ§Ã£o:\n{translated_text}")